<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AdaInNet: an adaptive inference engine for distributed deep neural networks offloading in IoT-FOG applications based on reinforcement learning | Amir Etefaghi Daryani</title>
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" />
  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
  <!-- Custom CSS -->
  <link rel="stylesheet" href="style.css" />
  <style>
    /* Main content offset */
    .main-content {
      margin-left: 270px;
      padding: 20px;
    }
    /* Rounded button styling */
    .btn-round {
      border-radius: 50px;
    }
    /* Output images carousel styling */
    .output-carousel .carousel-item {
      text-align: center;
      padding: 10px 0;
    }
    .output-carousel img {
      max-height: 250px;
      margin: 0 auto;
    }
    /* Center all text in the publication detail container */
    .publication-detail {
      text-align: center;
    }
    /* Additional spacing adjustments */
    .publication-detail h1,
    .publication-detail h3 {
      margin-top: 20px;
      margin-bottom: 10px;
    }
    .publication-detail p,
    .publication-detail pre {
      margin-bottom: 20px;
    }
  </style>
</head>
<body>
  <!-- Sidebar -->
  <div class="sidebar">
    <img src="images/me.jpg" alt="Profile Picture">
    <h5>Amir Etefaghi Daryani</h5>
    <p>Computer Vision Researcher</p>
    <hr>
    <div class="contact-info">
      <p><i class="fas fa-envelope"></i> amir.etefaghidar@ufl.edu</p>
      <p><i class="fas fa-map-marker-alt"></i> Gainesville, FL</p>
    </div>
    <hr>
    <div class="social-icons">
      <a href="https://www.linkedin.com/in/amir-etefaghi/" target="_blank"><i class="fab fa-linkedin"></i></a>
      <a href="https://github.com/amiretefaghi" target="_blank"><i class="fab fa-github"></i></a>
      <a href="https://scholar.google.com/citations?user=bo6Nt6kAAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i></a>
    </div>
  </div>

  <!-- Main Content -->
  <div class="main-content">
    <!-- Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-light bg-light mb-4">
      <div class="container-fluid">
        <a class="navbar-brand" href="index.html">Amir Etefaghi Daryani</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav ms-auto">
            <li class="nav-item"><a class="nav-link" href="about.html">About</a></li>
            <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
            <li class="nav-item"><a class="nav-link" href="projects.html">Projects</a></li>
            <li class="nav-item"><a class="nav-link" href="resume.html">Resume</a></li>
            <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Publication Detail Content -->
    <div class="publication-detail">
      <!-- Title -->
      <h1>AdaInNet: an adaptive inference engine for distributed deep neural networks offloading in IoT-FOG applications based on reinforcement learning</h1>
      
      <!-- Authors -->
      <p class="lead"><strong>Authors:</strong> Amir Etefaghi, Saeed Sharifian</p>
      
      <!-- Institution -->
      <p><strong>Institution:</strong> Amirkabir University of Technology</p>
      
      <!-- Conference Name and Year -->
      <p>The Journal of Supercomputing, 2022</p>
      
      <!-- Round Buttons for Paper and Code Links -->
      <div class="mb-4">
        <a href="https://link.springer.com/article/10.1007/s11227-022-04728-5" target="_blank" class="btn btn-primary btn-round me-2">
          <i class="fas fa-file-pdf"></i> Paper
        </a>
        <!-- <a href="https://github.com/example/code" target="_blank" class="btn btn-secondary btn-round">
          <i class="fab fa-github"></i> Code
        </a> -->
      </div>
      
      <!-- Big Image -->
      <div class="mb-4">
        <img src="images/AdaInNet.jpg" alt="Publication Main Image" class="img-fluid">
      </div>
      
      <!-- Abstract -->
      <div class="mb-4">
        <h3>Abstract</h3>
        <p>
          The increasing expansion of Internet-of-Things (IoT) in the world requires Big Data analytic infrastructures to produce valuable knowledge in IoT applications. IoT includes devices with limited resources, whereby it requires efficient platforms to process massive data obtained from sensors. Nowadays, many IoT applications such as audio and video recognition depend on state-of-the-art Deep Neural Networks (DNNs). Therefore, we need to execute DNNs on IoT devices. DNNs offer excellent recognition accuracy but they suffer from high computational and memory resource demands. Due to these constraints, currently, IoT applications that depend on deep learning are mostly offloaded to cloudlets and clouds. Offloading imposes extra network bandwidth consumption costs in addition to delayed response for IoT devices. In this paper, we propose a method that instead of using all layers of DNN for inference, only selects a subset of layers that provide sufficient accuracy for each task. We propose AdaInNet, a method to significantly reduce computational cost and network latency in DNN-based IoT applications while maintaining prediction accuracy based on Distributed DNNs (DDNNs). The method uses modified Distributed DNNs with early exits in order to minimize computation costs and network latency by selecting sub-layers or exit branches of DDNNs with early exits. We also proposed a hybrid Classifier-Wise (CW)—Interactive learning method for the training of DDNNs and Agent’s networks. Furthermore, we create a custom agent model for the Advantage Actor-Critic Deep Reinforcement Learning method in order to preserve recognition accuracy while utilizing a minimum number of layers. Finally, we execute the extensive numerical simulation, in order to evaluate and compare our proposed AdaInNet method with rival methods under standard CIFAR 100 and CIFAR 10 datasets and ResNet-110 and ResNet-32 DNNs which are used in IoT applications in previous works. The results provide strong quantitative evidence that the AdaInNet method not only accelerates inference but also reduces computational cost and latency.
        </p>
      </div>
    
      
      <!-- Bibtex -->
      <div class="mb-4">
        <h3>Bibtex</h3>
        <pre>
@article{etefaghidar2022,
  title={AdaInNet: an adaptive inference engine for distributed deep neural networks offloading in IoT-FOG applications based on reinforcement learning.},
  author={Etefaghi, A., Sharifian, Se},
  journal={The journal of supercomputing},
  year={2022}
}
        </pre>
      </div>
      
      <!-- Back Button -->
      <a href="publications.html" class="btn btn-secondary">Back to Publications</a>
    </div>
  </div>

  <!-- Footer -->
  <footer class="bg-dark text-white text-center py-3">
    <div class="container">
      <p>&copy; 2025 Amir Etefaghi Daryani. All Rights Reserved.</p>
    </div>
  </footer>

  <!-- Bootstrap JS Bundle -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>

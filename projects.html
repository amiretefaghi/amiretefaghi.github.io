<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Projects | Amir Etefaghi Daryani</title>
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css">
  <link rel="stylesheet" href="style.css" />
  <style>
    /* Navbar styling for consistency */
    .navbar {
      border-bottom: 1px solid #ddd;
    }
  </style>
</head>
<body>
  <!-- Sidebar -->
  <div class="sidebar">
    <img src="images/me.jpg" alt="Profile Picture">
    <div class="sidebar-info">
      <h5>Amir Etefaghi Daryani</h5>
      <p>Computer Vision Researcher</p>
    </div>
    <div class="contact-info">
      <p><i class="fas fa-envelope"></i> amir.etefaghidar@ufl.edu</p>
      <p><i class="fas fa-map-marker-alt"></i> Gainesville, FL</p>
    </div>
    <hr>
    <div class="social-icons">
      <a href="https://www.linkedin.com/in/amir-etefaghi/" target="_blank"><i class="fab fa-linkedin"></i></a>
      <a href="https://github.com/amiretefaghi" target="_blank"><i class="fab fa-github"></i></a>
      <a href="https://scholar.google.com/citations?user=bo6Nt6kAAAAJ&hl=en" target="_blank"><i class="fas fa-graduation-cap"></i></a>
      <!-- Add more social icons as needed -->
    </div>
  </div>  

  <!-- Main Content -->
  <div class="main-content">
    <nav class="navbar navbar-expand-lg navbar-light bg-light mb-4">
      <div class="container-fluid">
        <a class="navbar-brand" href="index.html">Amir Etefaghi Daryani</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
          <ul class="navbar-nav ms-auto">
            <li class="nav-item"><a class="nav-link" href="about.html">About</a></li>
            <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
            <li class="nav-item"><a class="nav-link active" href="projects.html">Projects</a></li>
            <li class="nav-item"><a class="nav-link" href="resume.html">Resume</a></li>
            <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Projects Content -->
    <h1>Projects</h1>
    <div class="row">
      <div class="col-md-4">
        <div class="card mb-4">
          <img src="images/CaMuViD.png" class="card-img-top" alt="Project 1">
          <div class="card-body">
            <h5 class="card-title">CaMuViD: Calibration-Free Multi-View Detection</h5>
            <p class="card-text">Multi-view object detection in crowded environments presents significant challenges, particularly for occlusion management across multiple camera views. 
              This project introduces a novel approach that extends conventional multi-view detection to operate directly within each camera's image space. 
              Our method finds objects bounding boxes for images from various perspectives without resorting to a birdâ€™s eye view (BEV) representation. 
              Thus, our approach removes the need for camera calibration by leveraging a learnable architecture that facilitates flexible transformations and improves feature fusion across perspectives to increase detection accuracy. 
              We used Python and PyTorch for implementation.</p>
            <a target="_blank" rel="noopener noreferrer" href="Camuvid.html" class="btn btn-primary">Learn More</a>
          </div>
        </div>
      </div>
      <div class="col-md-4">
        <div class="card mb-4">
          <!-- <img src="images/.png" class="card-img-top" alt="Project 1"> -->
          <div class="card-body">
            <h5 class="card-title">A Real-Time System for Correlating Belongings with Passengers Towards Real Airport</h5>
            <p class="card-text">Our research group is proud to contribute to the CLASP (Correlating Luggage and Specific Passengers) project, which is
              funded by the U.S. Department of Homeland Security Science and Technology Directorate through ALERT. This initiative
              aims to enhance security at checkpoints by utilizing advanced video analytics to automatically track passengers and their
              belongings. This project's implementation was based on Python and PyTorch.</p>
            <!-- <a href="Camuvid.html" class="btn btn-primary">Learn More</a> -->
          </div>
        </div>
      </div>
      <div class="col-md-4">
        <div class="card mb-4">
          <img src="images/EtoF.jpg" class="card-img-top" alt="Project 3">
          <div class="card-body">
            <h5 class="card-title">E2F-GAN: Eyes-to-Face Inpainting via Edge-Aware Coarse-to-Fine GANs</h5>
            <p class="card-text">Face inpainting is a challenging task aiming to fill the damaged or masked regions in face images with plausibly
              synthesized contents. Based on the given information, the reconstructed regions should look realistic and more
              importantly preserve the demographic and biometric properties of the individual. The aim of this project was to
              reconstruct the face based on the periocular region (eyes-to-face). This project's implementation was based on Python and Tensorlfow.</p>
            <a target="_blank" rel="noopener noreferrer" href="EtoF.html" class="btn btn-primary">Learn More</a>
          </div>
        </div>
      </div>
      <div class="col-md-4">
        <div class="card mb-4">
          <img src="images/IRL-Net.png" class="card-img-top" alt="Project 4">
          <div class="card-body">
            <h5 class="card-title">IRL-Net: Inpainted Region Localization Network via Spatial Attention</h5>
            <p class="card-text">Identifying manipulated regions in images is a challenging task due to the existence of very accurate image inpainting
              techniques leaving almost unnoticeable traces in tampered regions. These image inpainting methods can be used for
              multiple purposes (e.g., removing objects, reconstructing corrupted areas, eliminating various types of distortion, etc.)
              makes creating forensic detectors for image manipulation an extremely difficult and time-consuming procedure. The aim
              of this project was to localize the tampered regions manipulated by image inpainting methods.
              This project's implementation was based on Python and Tensorlfow.</p>
            <a target="_blank" rel="noopener noreferrer" href="IRL-Net.html" class="btn btn-primary">Learn More</a>
          </div>
        </div>
      </div>
      <div class="col-md-4">
        <div class="card mb-4">
          <img src="images/AdaInNet.jpg" class="card-img-top" alt="Project 5">
          <div class="card-body">
            <h5 class="card-title">IRL-Net: Inpainted Region Localization Network via Spatial Attention</h5>
            <p class="card-text">The increasing expansion of Internet-of-Things (IoT) in the world requires Big Data analytic infrastructures to produce valuable knowledge in IoT applications. 
              IoT includes devices with limited resources, whereby it requires efficient platforms to process massive data obtained from sensors. 
              Nowadays, many IoT applications such as audio and video recognition depend on state-of-the-art Deep Neural Networks (DNNs). 
              Therefore, we need to execute DNNs on IoT devices. DNNs offer excellent recognition accuracy but they suffer from high computational and memory resource demands. 
              Due to these constraints, currently, IoT applications that depend on deep learning are mostly offloaded to cloudlets and clouds. 
              Offloading imposes extra network bandwidth consumption costs in addition to delayed response for IoT devices. 
              In this project, we propose a method that instead of using all layers of DNN for inference, only selects a subset of layers that provide sufficient accuracy for each task. 
              This project's implementation was based on Python and Tensorlfow. </p>
            <a target="_blank" rel="noopener noreferrer" href="AdaInNet.html" class="btn btn-primary">Learn More</a>
          </div>
        </div>
      </div>
    </div>
    <!-- Footer -->
    <!-- <footer class="bg-dark text-white text-center py-3">
      <div class="container">
        <p>&copy; 2025 Amir Etefaghi Daryani. All Rights Reserved.</p>
      </div>
    </footer> -->
  </div>

  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>
